{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82d5eee",
   "metadata": {},
   "source": [
    "# ASSOCIATION RULES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec539ad2",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "#### Use the Online retail dataset to apply the association rules.\n",
    "## Data Preprocessing:\n",
    "#### Pre-process the dataset to ensure it is suitable for Association rules, this may include handling missing values, removing duplicates, and converting the data to appropriate format.  \n",
    "## Association Rule Mining:\n",
    "#### •\tImplement an Apriori algorithm using tool like python with libraries such as Pandas and Mlxtend etc.\n",
    "#### •\t Apply association rule mining techniques to the pre-processed dataset to discover interesting relationships between products purchased together.\n",
    "#### •\tSet appropriate threshold for support, confidence and lift to extract meaning full rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74234be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                           Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                           --------------  ----- \n",
      " 0   shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil  7500 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 58.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
       " 0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
       " 1                                            chutney                                                                                                                                                                             \n",
       " 2                                     turkey,avocado                                                                                                                                                                             \n",
       " 3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
       " 4                                     low fat yogurt                                                                                                                                                                             )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Online retail.csv\")\n",
    "\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633cedb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['burgers', 'meatballs', 'eggs'],\n",
       " ['chutney'],\n",
       " ['turkey', 'avocado'],\n",
       " ['mineral water', 'milk', 'energy bar', 'whole wheat rice', 'green tea'],\n",
       " ['low fat yogurt']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the single-column data into transactions\n",
    "df_cleaned = df.iloc[:, 0].str.split(',', expand=False)\n",
    "\n",
    "# Convert to a list of lists format\n",
    "transactions = df_cleaned.tolist()\n",
    "\n",
    "# Display a sample of processed transactions\n",
    "transactions[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c7d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (3.7.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f35890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(ground beef)</td>\n",
       "      <td>(spaghetti)</td>\n",
       "      <td>0.098267</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.398915</td>\n",
       "      <td>2.290857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>1.373959</td>\n",
       "      <td>0.624888</td>\n",
       "      <td>0.168096</td>\n",
       "      <td>0.272176</td>\n",
       "      <td>0.312015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(olive oil)</td>\n",
       "      <td>(spaghetti)</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.348884</td>\n",
       "      <td>2.003547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011487</td>\n",
       "      <td>1.268387</td>\n",
       "      <td>0.536127</td>\n",
       "      <td>0.105716</td>\n",
       "      <td>0.211597</td>\n",
       "      <td>0.240292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(soup)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.050533</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.023067</td>\n",
       "      <td>0.456464</td>\n",
       "      <td>1.915771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>1.401441</td>\n",
       "      <td>0.503458</td>\n",
       "      <td>0.086804</td>\n",
       "      <td>0.286449</td>\n",
       "      <td>0.276637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(burgers)</td>\n",
       "      <td>(eggs)</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.179733</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.330275</td>\n",
       "      <td>1.837585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>1.224782</td>\n",
       "      <td>0.499351</td>\n",
       "      <td>0.120941</td>\n",
       "      <td>0.183528</td>\n",
       "      <td>0.245256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(tomatoes)</td>\n",
       "      <td>(spaghetti)</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.306043</td>\n",
       "      <td>1.757520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>1.190083</td>\n",
       "      <td>0.462663</td>\n",
       "      <td>0.094465</td>\n",
       "      <td>0.159723</td>\n",
       "      <td>0.213129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(olive oil)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.027467</td>\n",
       "      <td>0.417850</td>\n",
       "      <td>1.753707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>1.308483</td>\n",
       "      <td>0.460018</td>\n",
       "      <td>0.099325</td>\n",
       "      <td>0.235756</td>\n",
       "      <td>0.266563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(ground beef)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.098267</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.040933</td>\n",
       "      <td>0.416554</td>\n",
       "      <td>1.748266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>1.305576</td>\n",
       "      <td>0.474647</td>\n",
       "      <td>0.138475</td>\n",
       "      <td>0.234054</td>\n",
       "      <td>0.294175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(cooking oil)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.051067</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.020133</td>\n",
       "      <td>0.394256</td>\n",
       "      <td>1.654683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>1.257517</td>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.074789</td>\n",
       "      <td>0.204782</td>\n",
       "      <td>0.239378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(chicken)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.594852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>1.228602</td>\n",
       "      <td>0.396790</td>\n",
       "      <td>0.082769</td>\n",
       "      <td>0.186067</td>\n",
       "      <td>0.237846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(frozen vegetables)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.095333</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.035733</td>\n",
       "      <td>0.374825</td>\n",
       "      <td>1.573133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>1.218433</td>\n",
       "      <td>0.402718</td>\n",
       "      <td>0.119964</td>\n",
       "      <td>0.179273</td>\n",
       "      <td>0.262399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            antecedents      consequents  antecedent support  \\\n",
       "8         (ground beef)      (spaghetti)            0.098267   \n",
       "18          (olive oil)      (spaghetti)            0.065733   \n",
       "14               (soup)  (mineral water)            0.050533   \n",
       "0             (burgers)           (eggs)            0.087200   \n",
       "19           (tomatoes)      (spaghetti)            0.068400   \n",
       "11          (olive oil)  (mineral water)            0.065733   \n",
       "7         (ground beef)  (mineral water)            0.098267   \n",
       "4         (cooking oil)  (mineral water)            0.051067   \n",
       "2             (chicken)  (mineral water)            0.060000   \n",
       "6   (frozen vegetables)  (mineral water)            0.095333   \n",
       "\n",
       "    consequent support   support  confidence      lift  representativity  \\\n",
       "8             0.174133  0.039200    0.398915  2.290857               1.0   \n",
       "18            0.174133  0.022933    0.348884  2.003547               1.0   \n",
       "14            0.238267  0.023067    0.456464  1.915771               1.0   \n",
       "0             0.179733  0.028800    0.330275  1.837585               1.0   \n",
       "19            0.174133  0.020933    0.306043  1.757520               1.0   \n",
       "11            0.238267  0.027467    0.417850  1.753707               1.0   \n",
       "7             0.238267  0.040933    0.416554  1.748266               1.0   \n",
       "4             0.238267  0.020133    0.394256  1.654683               1.0   \n",
       "2             0.238267  0.022800    0.380000  1.594852               1.0   \n",
       "6             0.238267  0.035733    0.374825  1.573133               1.0   \n",
       "\n",
       "    leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
       "8   0.022088    1.373959       0.624888  0.168096   0.272176    0.312015  \n",
       "18  0.011487    1.268387       0.536127  0.105716   0.211597    0.240292  \n",
       "14  0.011026    1.401441       0.503458  0.086804   0.286449    0.276637  \n",
       "0   0.013127    1.224782       0.499351  0.120941   0.183528    0.245256  \n",
       "19  0.009023    1.190083       0.462663  0.094465   0.159723    0.213129  \n",
       "11  0.011805    1.308483       0.460018  0.099325   0.235756    0.266563  \n",
       "7   0.017520    1.305576       0.474647  0.138475   0.234054    0.294175  \n",
       "4   0.007966    1.257517       0.416947  0.074789   0.204782    0.239378  \n",
       "2   0.008504    1.228602       0.396790  0.082769   0.186067    0.237846  \n",
       "6   0.013019    1.218433       0.402718  0.119964   0.179273    0.262399  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Convert transactions into a format suitable for apriori\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "min_support = 0.02  # Setting a minimum support threshold\n",
    "frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "min_confidence = 0.3  # Setting minimum confidence\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Display the top rules sorted by lift\n",
    "rules.sort_values(by=\"lift\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aebde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42ddaff1",
   "metadata": {},
   "source": [
    "## Analysis and Interpretation:\n",
    "#### •\tAnalyse the generated rules to identify interesting patterns and relationships between the products.\n",
    "#### •\tInterpret the results and provide insights into customer purchasing behaviour based on the discovered rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364347eb",
   "metadata": {},
   "source": [
    "### Analysis of Association Rules\n",
    "\n",
    "#### Support: The proportion of transactions that contain a specific itemset. Higher support means the itemset appears frequently.\n",
    "#### Confidence: The probability that if a customer buys item A, they will also buy item B. Higher confidence suggests a strong relationship.\n",
    "#### Lift: Measures how much more likely item B is bought when item A is purchased, compared to random chance. Lift > 1 indicates a strong positive association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0df8a",
   "metadata": {},
   "source": [
    "## Steps for Interpretation\n",
    "### Identify strong rules\n",
    "#### Sort the rules by lift to find the most impactful ones.\n",
    "#### Look for high confidence values (e.g., above 0.5) to ensure reliability.\n",
    "\n",
    "### Find complementary products\n",
    "#### If \"mineral water → green tea\" has a high lift and confidence, it suggests customers who buy mineral water often buy green tea.\n",
    "#### Such insights can be used for bundling products or promotions.\n",
    "\n",
    "### Spot substitute products\n",
    "#### If \"almonds → cashews\" appears frequently, it may indicate customers switch between these items.\n",
    "\n",
    "### Understand customer segments\n",
    "#### If health-related products (e.g., \"low-fat yogurt → honey\") frequently appear together, it indicates a segment of health-conscious buyers.\n",
    "#### If luxury items (e.g., \"salmon → olive oil\") show up together, they might appeal to premium customers.\n",
    "\n",
    "### Marketing and Recommendation Strategies\n",
    "#### Use high-lift rules for product recommendations (e.g., “People who bought this also bought...”).\n",
    "#### Offer discounts or combo deals on frequently bought-together items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d5e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd9b8b0",
   "metadata": {},
   "source": [
    "## Interview Questions:\n",
    "### 1.\tWhat is lift and why is it important in Association rules?\n",
    "#### Definition:\n",
    "#### Lift is a measure used in association rule mining to evaluate the strength of a rule compared to the expected occurrence of the consequent item, assuming the antecedent and consequent are independent. It helps determine how much more likely the consequent (B) is to appear when the antecedent (A) is present compared to when A and B are independent.\n",
    "\n",
    "#### Formula:\n",
    "#### Lift(A⇒B)= Support(A∩B) / Support(A)×Support(B)\n",
    " \n",
    "#### Where:\n",
    "#### Support(A ∩ B) = Probability of both A and B occurring together.\n",
    "#### Support(A) = Probability of A occurring.\n",
    "#### Support(B) = Probability of B occurring.\n",
    "\n",
    "#### Importance of Lift:\n",
    "#### Measures Rule Strength: A higher lift indicates a stronger association between A and B.\n",
    "#### Interpretability:\n",
    "#### Lift = 1 → No association (A and B are independent).\n",
    "#### Lift > 1 → Positive correlation (A increases the likelihood of B).\n",
    "#### Lift < 1 → Negative correlation (A reduces the likelihood of B).\n",
    "#### Better than Confidence Alone: Unlike confidence, which only considers the frequency of B given A, lift accounts for how common B is in general, making it more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e188731",
   "metadata": {},
   "source": [
    "### 2.\tWhat is support and Confidence. How do you calculate them?\n",
    "#### 1. Support\n",
    "#### Definition:\n",
    "#### Support measures how frequently an itemset appears in the dataset. It helps in identifying commonly occurring itemsets.\n",
    "\n",
    "#### Formula:\n",
    "#### Support(𝐴)=Number of transactions containing A / Total number of transactions\n",
    "\n",
    "#### or for a rule A⇒B:\n",
    "\n",
    "#### Support(𝐴⇒𝐵)=Number of transactions containing both A and B / Total number of transactions\n",
    "\n",
    "#### Example:\n",
    "#### If we have 10,000 transactions and \"Milk & Bread\" appear together in 800 transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f608b0",
   "metadata": {},
   "source": [
    "#### 2. Confidence\n",
    "#### Definition:\n",
    "#### Confidence measures how often item B appears in transactions that already contain item A. It indicates the likelihood of B occurring given that A is present.\n",
    "\n",
    "#### Formula:\n",
    "\n",
    "#### Confidence(A⇒B)= Support(A∩B) / Support(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea540d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db5c271",
   "metadata": {},
   "source": [
    "### 3.\tWhat are some limitations or challenges of Association rules mining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212aa51e",
   "metadata": {},
   "source": [
    "#### Association rule mining is a powerful technique for discovering interesting relationships between variables in large datasets. However, it comes with several limitations and challenges, including:\n",
    "\n",
    "#### High Computational Complexity – The process of generating frequent itemsets and association rules can be computationally expensive, especially for large datasets with many attributes.\n",
    "\n",
    "#### Handling Large Datasets – The number of possible itemsets grows exponentially with the number of items, making it challenging to process large-scale databases efficiently.\n",
    "\n",
    "#### Choosing the Right Support and Confidence Thresholds – Setting appropriate minimum support and confidence values is often difficult. If thresholds are too high, important rules may be missed; if too low, too many trivial or irrelevant rules may be generated.\n",
    "\n",
    "#### Generating Too Many Rules – Many association rule mining algorithms generate an excessive number of rules, making it difficult to extract meaningful insights from the results.\n",
    "\n",
    "#### Redundant and Uninteresting Rules – Many discovered rules may be redundant or uninteresting, providing little new information to decision-makers.\n",
    "\n",
    "#### Lack of Temporal Considerations – Traditional association rule mining does not take into account the sequence or time-order of transactions, which can be important in some applications.\n",
    "\n",
    "#### Handling Continuous and Numeric Data – Association rule mining is primarily designed for categorical data, and preprocessing is often required to discretize numerical attributes, which can lead to loss of information.\n",
    "\n",
    "#### Scalability Issues – As the dataset grows, the memory and processing power required to compute frequent itemsets and generate rules increase significantly.\n",
    "\n",
    "#### Interpretability of Rules – Some discovered rules may be difficult to interpret or apply in real-world decision-making.\n",
    "\n",
    "#### Ignoring Negative Associations – Most algorithms focus on finding positive associations, ignoring negative correlations (e.g., if one item is purchased, another is less likely to be purchased).\n",
    "\n",
    "#### Data Sparsity – In datasets with a large number of unique items (e.g., e-commerce transactions), meaningful associations may be rare, leading to difficulties in mining useful rules.\n",
    "\n",
    "#### Privacy Concerns – Mining associations in sensitive datasets (e.g., medical or financial data) may pose privacy risks and ethical concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34568676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
